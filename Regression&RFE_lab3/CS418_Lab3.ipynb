{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFV8OqC2BF7c"
   },
   "source": [
    "# Lab 3: Scikit Learn and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYCSkPWHBF8J"
   },
   "source": [
    "\n",
    "### [Read an follow the prelab before answering the questions here](https://drive.google.com/file/d/1RVGIYL9xloKfn9SPoJoxXSiKdRhuj9RD/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0dqshH4BF8d"
   },
   "source": [
    "\n",
    "## Academic Integrity Guidelines \n",
    "This lab is an individual assignment (like all the other labs). You should NOT work with your project teammate nor any other classmate. If you have questions, please ask us on Piazza.\n",
    "You must reference (including URLs) of any resources other than those linked to in the assignment, or provided by the professor or TA. \n",
    "\n",
    "\n",
    "##To submit this assignment:\n",
    "1.\tPrint your Jupyter Notebook as a PDF and upload it to Gradescope. **Make sure that each line of code has 80 characters maximum and that all your plots and text are properly displayed in the pdf.**\n",
    "2.\tExport your Jupyter Notebook as a python file (.py) and upload it to Gradescope. **If your pdf does not show your text and plots properly, submit your jupyter notebook file also (.ipynb)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4fjxQANBF8m"
   },
   "source": [
    "#### Exercise 3.1 ( 20 pts)\n",
    "\n",
    "Perform the following tasks (TODO):\n",
    "\n",
    "1. Load this Boston housing dataset: \n",
    " * [info](https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.names)\n",
    " * [housing.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv) \n",
    "\n",
    "2. Display the first 10 rows of the dataset with column names as headers as it is shown in the [info](https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.names) file\n",
    "\n",
    "3. Using your own judgment, select one of the 13 columns as a predictor for MEDV(Median value of owner-occupied homes in $1000's).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "FVILd63qBF8n",
    "outputId": "3bea82c0-b53f-4395-a780-58061325f991"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e7220aa4-3e31-49c3-8b3b-445a76e9fc0e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.22489</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.377</td>\n",
       "      <td>94.3</td>\n",
       "      <td>6.3467</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>392.52</td>\n",
       "      <td>20.45</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7220aa4-3e31-49c3-8b3b-445a76e9fc0e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e7220aa4-3e31-49c3-8b3b-445a76e9fc0e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e7220aa4-3e31-49c3-8b3b-445a76e9fc0e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242.0   \n",
       "1  0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242.0   \n",
       "2  0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222.0   \n",
       "3  0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222.0   \n",
       "4  0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222.0   \n",
       "5  0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311.0   \n",
       "6  0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311.0   \n",
       "7  0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311.0   \n",
       "8  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311.0   \n",
       "9  0.22489  12.5   7.87     0  0.524  6.377   94.3  6.3467    5  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     17.8  396.90   9.14  21.6  \n",
       "1     17.8  392.83   4.03  34.7  \n",
       "2     18.7  394.63   2.94  33.4  \n",
       "3     18.7  396.90   5.33  36.2  \n",
       "4     18.7  394.12   5.21  28.7  \n",
       "5     15.2  395.60  12.43  22.9  \n",
       "6     15.2  396.90  19.15  27.1  \n",
       "7     15.2  386.63  29.93  16.5  \n",
       "8     15.2  386.71  17.10  18.9  \n",
       "9     15.2  392.52  20.45  15.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "# TODO: Load the dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('housing.csv')\n",
    "# import pandas as pd\n",
    "# df = pd.read_html('https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv')\n",
    "df.columns =['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "# TODO: Display first 10 rows \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEhuPNknS-iR"
   },
   "source": [
    "####Which column did you choose and why?\n",
    "\n",
    "**I have chosen the column - RM. Because number of rooms is usually directly proportional to a home's value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_zC8wRPS8jz"
   },
   "source": [
    "\n",
    "4. Make a linear regression model with the feature you chose. Use `train_test_split` to keep 20% of the data for testing.\n",
    "5. Use your model to predict values for test set and print the predictions for the first 10 instances of the test data and compare them with actual values. (e.g. a table with columns predicted value and actual value).\n",
    "6. Print the coefficient value and its corresponding feature name (e.g.  CRIM  0.00632)  \n",
    "7. Calculate training-MSE, testing-MSE, and R-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAMQUXnNTZGe",
    "outputId": "03c6f444-a6a1-4cf9-b97a-ca1413b881cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values vs Actual values\n",
      "{'Predicted Values': array([[34.54026669],\n",
      "       [24.51628901],\n",
      "       [31.7317866 ],\n",
      "       [20.09160811],\n",
      "       [19.43806243],\n",
      "       [17.21247444],\n",
      "       [14.83674757],\n",
      "       [32.99471947],\n",
      "       [24.05704069],\n",
      "       [23.58896068]]), 'Actual Values':      MEDV\n",
      "281  46.0\n",
      "158  23.3\n",
      "262  31.0\n",
      "293  21.7\n",
      "15   23.1\n",
      "404   5.0\n",
      "488   7.0\n",
      "267  43.5\n",
      "129  19.2\n",
      "90   22.0}\n",
      "----------------------------------------------------------------\n",
      "Model coefficient with feature names\n",
      "RM\n",
      "[[8.83169839]]\n",
      "----------------------------------------------------------------\n",
      "Model intercept\n",
      "[-32.97806754]\n",
      "----------------------------------------------------------------\n",
      "r-squared\n",
      "0.5634007372139881\n",
      "----------------------------------------------------------------\n",
      "MSE for training : 45.97878512680088\n",
      "MSE for testing : 34.68826382068348\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# TODO: Select ONE FEATURE for linear regression\n",
    "X = df[['RM']]\n",
    "y = df[['MEDV']]\n",
    "# TODO: Split the data into training/testing sets\n",
    "X_train,X_test , y_train, y_test = train_test_split(\n",
    "                                     X, y, test_size = 0.20)\n",
    "lr = LinearRegression()\n",
    "# df_X_train.shape\n",
    "# df_y_train.shape\n",
    "# TODO: Train the model \n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Make predictions on test data \n",
    "pred = lr.predict(X_test)\n",
    "# print(tabulate(data, headers=[\"Pos\", \"Predicted Values\", \"Actual Values\"]))\n",
    "print('Predicted values vs Actual values')\n",
    "d = {'Predicted Values': pred[:10], 'Actual Values': y_test[:10]}\n",
    "print(d)\n",
    "print('----------------------------------------------------------------')\n",
    "# TODO: print the model coefficient with feature names\n",
    "print('Model coefficient with feature names')\n",
    "# print(X_train.columns)\n",
    "for col in X_train.columns:\n",
    "    print(col)\n",
    "print(lr.coef_)\n",
    "print('----------------------------------------------------------------')\n",
    "# TODO: print the model intercept\n",
    "print('Model intercept')\n",
    "print(lr.intercept_)\n",
    "print('----------------------------------------------------------------')\n",
    "# TODO: print the r-squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, pred)\n",
    "print('r-squared')\n",
    "print(r2)\n",
    "print('----------------------------------------------------------------')\n",
    "# TODO: print the mean squared error for training\n",
    "from sklearn.metrics import mean_squared_error\n",
    "pred_train = lr.predict(X_train)\n",
    "print('MSE for training : ' + str(mean_squared_error(y_train, pred_train)))\n",
    "# TODO: print the mean squared error for testing\n",
    "print('MSE for testing : ' + str(mean_squared_error(y_test, pred)))\n",
    "print('----------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e489iZCWTZVj"
   },
   "source": [
    "8. Make a linear regression model with **all the features** in the dataset (MEDV is not a feature, it is the value to predict). Use `train_test_split` to keep 20% of the data for testing.\n",
    "9. Use your model to predict values for test set and print the predictions for the first 10 instances of the test data and compare them with actual values.\n",
    "10. Print the coefficient values and their corresponding feature name \n",
    "11. Calculate training-MSE, testing-MSE, and R-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3DxKFSrUbhz",
    "outputId": "f5cb88fd-624c-4189-8a57-58ffc485cc3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficient with feature names\n",
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT'],\n",
      "      dtype='object')  [-1.10395242e-01  3.29866184e-02  1.87221062e-02  3.17535918e+00\n",
      " -2.01023731e+01  3.18090448e+00  2.25493116e-02 -1.36785138e+00\n",
      "  3.16303679e-01 -9.95787688e-03 -1.10042829e+00  7.90313769e-03\n",
      " -6.40724075e-01]\n",
      "----------------------------------------------------------------\n",
      "Model intercept\n",
      "43.55405096702418\n",
      "----------------------------------------------------------------\n",
      "r-squared\n",
      "0.7545604410992675\n",
      "----------------------------------------------------------------\n",
      "MSE for training : 22.753865549060905\n",
      "MSE for testing : 20.414164512408018\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# TODO: Select ALL THE FEATURES for linear regression\n",
    "X1 = df[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
    "       'PTRATIO', 'B', 'LSTAT']]\n",
    "y1 = df['MEDV']\n",
    "# TODO: Split the data into training/testing sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2)\n",
    "# TODO: Train the model \n",
    "lm = LinearRegression()\n",
    "lm.fit(X1_train,y1_train)\n",
    "# TODO: Make predictions on test data \n",
    "pred1 = lm.predict(X1_test)\n",
    "# TODO: print the model coefficient with feature names\n",
    "print('Model coefficient with feature names')\n",
    "print(str(X1_train.columns) + '  ' + str(lm.coef_))\n",
    "print('----------------------------------------------------------------')\n",
    "# TODO: print the model intercept\n",
    "print('Model intercept')\n",
    "print(lm.intercept_)\n",
    "print('----------------------------------------------------------------')\n",
    "# TODO: print the r-squared\n",
    "# from sklearn.metrics import r2_score\n",
    "r2_1 = r2_score(y1_test, pred1)\n",
    "print('r-squared')\n",
    "print(r2_1)\n",
    "print('----------------------------------------------------------------')\n",
    "# TODO: print the mean squared error for training\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "pred1_train = lm.predict(X1_train)\n",
    "print('MSE for training : ' + str(mean_squared_error(y1_train, pred1_train)))\n",
    "# TODO: print the mean squared error for testing\n",
    "print('MSE for testing : ' + str(mean_squared_error(y1_test, pred1)))\n",
    "print('----------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FlcXyWoVRb-"
   },
   "source": [
    "#### Compare the two models (with all the features versus one feature). Which model has a better performance? Why?\n",
    "\n",
    "\n",
    "**The model with all the features is the better performing one. It's mean squared error is lesser than the one with a single feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGV5xFIVBF8r"
   },
   "source": [
    "#### Exercise 3.2 (15 pts)\n",
    "\n",
    "1.   Use `RFE` to select the two most important features.\n",
    "2.   Make a Linear regression model using the features that `RFE` selected. \n",
    "3.   Calculate and print both train and test MSE and R-squared values, and compare this model with the models from 3.1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2u_EeQTK5Iv",
    "outputId": "09aef2c1-cee9-40c5-b90b-ae05f131b258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 Score : 0.5556249881405007\n",
      "----------------------------------------------------------------\n",
      "MSE for training : 39.660419359513234\n",
      "MSE for testing : 37.90592035165051\n",
      "----------------------------------------------------------------\n",
      "columns selected by rfe\n",
      "Column: 4\n",
      "Column: 5\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here \n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "rfe.fit(X1,y1)\n",
    "Xrfe = rfe.transform(X1)\n",
    "# Split the data into training/testing sets\n",
    "Xrfe_train, Xrfe_test, yrfe_train, yrfe_test = train_test_split(Xrfe, y1, test_size=0.2)\n",
    "# Train the model \n",
    "lrrfe = LinearRegression()\n",
    "lrrfe.fit(Xrfe_train,yrfe_train)\n",
    "# Make predictions on test data \n",
    "predrfe = lrrfe.predict(Xrfe_test)\n",
    "# print the r-squared\n",
    "r2_rfe = r2_score(yrfe_test, predrfe)\n",
    "print('r2 Score : ' + str(r2_rfe))\n",
    "print('----------------------------------------------------------------')\n",
    "# print the mean squared error for training\n",
    "predrfe_train = lrrfe.predict(Xrfe_train)\n",
    "print('MSE for training : ' + str(mean_squared_error(yrfe_train, predrfe_train)))\n",
    "# print the mean squared error for testing\n",
    "print('MSE for testing : ' + str(mean_squared_error(yrfe_test, predrfe)))\n",
    "print('----------------------------------------------------------------')\n",
    "# Print the columns selected by rfe\n",
    "print('columns selected by rfe')\n",
    "for i in range(X1.shape[1]):\n",
    "  if rfe.support_[i] == True:\n",
    "\t  print('Column: %d' % (i))\n",
    "print('----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oy69YfwLK7Fa"
   },
   "source": [
    "#### Explain your observation. What are the important features found using RFE?\n",
    "\n",
    "**The two most important features found were columns 5 and 6 (considering indexing from 0) i.e. NOX and RM.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6YpdL-UBF8o"
   },
   "source": [
    "#### Compare the three models (with one feature, two features and all the features versus). Which model has a better performance? \n",
    "\n",
    "\n",
    "**The model with all the features seem to have the least MSE thus best performance. The model with two features performs better than the one with single feature but occassionally performs bad. This could be due to the changing samples in the train-test split.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqiveBNFBF8t"
   },
   "outputs": [],
   "source": [
    "# Your code goes here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPKkuAxDBF8u"
   },
   "source": [
    "### Linear regression on the Boston house price dataset\n",
    "\n",
    "Now it's your turn to perform a linear regression on the **Boston housing** dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eF5VNbQaBF8z"
   },
   "source": [
    " #### Exercise 3.3  ( 15 pts)\n",
    " \n",
    "Let's build models with different training sizes to predict the house prices for boston house dataset. Each model should use all the available features. The goal is to train multiple linear regression models for the following train-test splits and calculate and visualize their MSE:\n",
    "\n",
    "1.   30% training, 70% testing \n",
    "2.   40% training, 60% testing\n",
    "3.   50% training, 50% testing\n",
    "4.   60% training, 40% testing\n",
    "5.   70% training, 30% testing\n",
    "6.   80% training, 20% testing. (done previously)\n",
    "\n",
    "\n",
    "*Note: For simplicity, make a function that builds and fits the linear model and returns MSE for test.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "f3WIH-IqBF80"
   },
   "outputs": [],
   "source": [
    "#Your code goes here\n",
    "def modelBuilding(x, Y, train_size):\n",
    "  # Split the data into training/testing sets\n",
    "  x_train, x_test, Y_train, Y_test = train_test_split(x, Y, test_size=(1-train_size))\n",
    "  # TODO: Train the model \n",
    "  lm = LinearRegression()\n",
    "  lm.fit(x_train,Y_train)\n",
    "  # TODO: Make predictions on test data \n",
    "  pred1 = lm.predict(x_test)\n",
    "  # print the mean squared error for testing\n",
    "  return (mean_squared_error(Y_test, pred1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGIbHaDWXRia"
   },
   "source": [
    "\n",
    "Plot the test MSE values for all models with respect to the training size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "lUGUS1ItXSLR",
    "outputId": "4b70dc23-3366-435d-ccb5-ab88131b9f9d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Your code goes here\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "xaxis = ['30','40','50','60','70','80']\n",
    "mse_values = []\n",
    "for i in xaxis:\n",
    "  tr_size = (int(i)/100)\n",
    "  mse_values.append(modelBuilding(X1,y1,tr_size))\n",
    "ax.set_ylabel('MSE values')\n",
    "ax.set_xlabel('Training sizes in percentage')\n",
    "ax.bar(xaxis,mse_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csYHO08dBF85"
   },
   "source": [
    " #### Exercise 3.4  ( 30 pts)\n",
    " \n",
    " Next, we want to use `RFE` to find the best set of features for prediction. When we used `RFE` in 3.2, we chose an arbitrary value for number of features. In practice, we don't know the best number of features to select for `RFE`, so we have to test different values. In this case, the number of features is the hyperparameter that we want to tune. \n",
    "Typically, we use cross validation for tuning hyperparameters. \n",
    "\n",
    "Recall that cross validation is a technique where we split our data into equal folds and then use one fold for testing and the rest for training. We can use `KFold` [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) form scikit learn `model_selection` to split our data into desired folds. We can also use `cross_val_score` [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) to evaluate a score by cross validation. \n",
    " \n",
    "\n",
    "For this exercise, use `RFE` with cross-validation (K = 5 aka 5fold) to find the best set of features for prediction. \n",
    "\n",
    "\n",
    " - Make an RFE model with i number of features\n",
    " - Create a 5-fold CV on the data set \n",
    " - Fit the model with Cross validation using the best features and store the MSE values\n",
    " - Draw a box plot for MSE values of each model and pick the best number of features\n",
    "\n",
    "Note that the Boston housing data set contains 13 features, so you must create 13 models (one per each i best features selected with RFE) and use that model with 5-fold CV. At the end, you should have 13 models with 5 MSE values for each model (results of CV). \n",
    "\n",
    "Plot a side-by-side boxplot and compare the distribution of MSE values for these 13 models. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "cB4GaQG8BF86",
    "outputId": "b227cb7c-8e14-4c4e-8100-02909f23f858"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Your code goes here\n",
    "list_scores = []\n",
    "for i in range(13):\n",
    "  mdl = LinearRegression()\n",
    "  rfekf = RFE(mdl, n_features_to_select=i+1)\n",
    "  rfekf.fit(X1,y1)\n",
    "  Xrfekf = rfekf.transform(X1)\n",
    "  folds = KFold(n_splits = 5)\n",
    "  scores = cross_val_score(lm, Xrfekf, y1, scoring='neg_mean_squared_error', cv=folds)\n",
    "  scores = scores * -1\n",
    "  list_scores.append(scores)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(list_scores,meanline = True)\n",
    "\n",
    "ax.set_title('Box plot of MSE vs Number of best features with K fold Cross validation of K = 5')\n",
    "ax.set_xlabel('Number of best features')\n",
    "ax.set_ylabel('MSE')\n",
    "xticklabels=['1','2','3','4','5','6','7','8','9','10','11','12','13']\n",
    "ax.set_xticklabels(xticklabels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76Hx-4CkYFul"
   },
   "source": [
    "Based on the previous plot, pick the model with lowest average MSE as the best result. What is the best number of features? Which features are selected?\n",
    "\n",
    "**The model with the 6 best features has the lowest average MSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phgO08267bbg",
    "outputId": "a7815372-1506-4e09-cb80-8a78b8c1e9d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 3\n",
      "Column: 4\n",
      "Column: 5\n",
      "Column: 7\n",
      "Column: 10\n",
      "Column: 12\n"
     ]
    }
   ],
   "source": [
    "# Print the columns selected by rfe\n",
    "md = LinearRegression()\n",
    "rfe = RFE(mdl, n_features_to_select=6)\n",
    "rfe.fit(X1,y1)\n",
    "print('Columns selected by rfe')\n",
    "for i in range(X1.shape[1]):\n",
    "  if rfe.support_[i] == True:\n",
    "\t  print('Column: %d' % (i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVGhvGK59P_Z"
   },
   "source": [
    "**The columns 4,5,6,8,11 and 13 (considering zero indexing) i.e. CHAS, NOX, RM, DIS, PTRATIO and LSTAT have been selected as the 6 best features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GC4-prZBF88"
   },
   "source": [
    "#### Exercise 3.5 (10 pts)\n",
    "\n",
    "Another way of doing RFE with CV is using `RFECV` [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV) which performs the same task as `RFE` while performing a cross validation task. \n",
    "Use `RFECV` to find the best number of features for a regression model for Boston housing data set.  Which features are selected? (you can use `ranking_` attribute)\n",
    "\n",
    "Some Notes: \n",
    "\n",
    "- For `scoring` parameter you can use `neg_mean_squared_error` to get MSE. You can read [model evaluation documentation](https://scikit-learn.org/stable/modules/model_evaluation.html) to learn what values you can pass for this parameter\n",
    "\n",
    "- The default value for `cv` parameter in `RFECV` model is 5-fold cross-validation\n",
    "\n",
    "- Your results for RFE may vary (values with different numerical precision) given the stochastic nature of the algorithm and evaluation process.\n",
    "\n",
    "- Specifying random_state parameter ensures the same random partitions are used across different runs \n",
    "\n",
    "- Read the documentation to learn more about parameters and attributes for each model we discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdUAWe1pBF89",
    "outputId": "f673cc59-734e-4cf2-d04b-7b5e2bfdf36f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 6, 1, 1, 1, 8, 1, 2, 5, 1, 7, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code goes here\n",
    "from sklearn.feature_selection import RFECV\n",
    "mdl = LinearRegression()\n",
    "selector = RFECV(mdl, cv=5, scoring ='neg_mean_squared_error' )\n",
    "selector = selector.fit(X1, y1)\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C46wCGWpBF89"
   },
   "source": [
    "###Which features are selected?\n",
    "\n",
    "**The features selected by RFECV are the columns 4,5,6,8,11 and 13 i.e. CHAS, NOX, RM, DIS, PTRATIO and LSTAT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIe-zjt0BF8w"
   },
   "source": [
    "#### Exercise 3.6 ( 10 pts)\n",
    "\n",
    "The Boston housing prices dataset has an ethical problem. Describe here why.\n",
    "\n",
    "###**The inclusion of the column 'B' which stands for Black proportion of population is the ethical problem here. The authors of the dataset, in their paper talk about their assumption that increase in B should negatively affect MEDV. The inclusion of this column also will lead to systemic racism if used official systems.[1]**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtoDUgQSGsir"
   },
   "source": [
    "**REFERENCES:**\n",
    "\n",
    "[1] https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kj5pbEK7G2BK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bIe-zjt0BF8w"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
